random.order = F,    # 단어 출력위치
rot.per = .1,        # 90도 회전 단어 비율
colors = pal2)       # 단어 색색
wordcloud(names(wordcount),    # 단어
freq = wordcount,    # 단어 빈도
scale = c(6,0.7),    # 단어 폰트 크기(최대,최소)
min.freq = 3,        # 단어 최소 빈도
random.order = F,    # 단어 출력위치
rot.per = .1,        # 90도 회전 단어 비율
colors = pal3)       # 단어 색색
#     6.2 생락된 단어를 사전에 등재
buildDictionary(ext_dic = 'woorimalsam',
user_dic = data.frame('정치','ncn'),
replace_usr_dic = T)
noun <- sapply(text, extractNoun, USE,NAMES = F)
noun2 <- unlist(noun)
#     6.1 불필요한 단어 삭제
noun2 <- noun2[nchar(noun2) > 1]
noun2 <- gsub('하지', '', noun2)
noun2 <- gsub('때문', '', noun2)
wordcount <- table(noun2)
wordcount
sort(wordcount)
wordcloud(names(wordcount),    # 단어
freq = wordcount,    # 단어 빈도
scale = c(6,0.7),    # 단어 폰트 크기(최대,최소)
min.freq = 3,        # 단어 최소 빈도
random.order = F,    # 단어 출력위치
rot.per = .1,        # 90도 회전 단어 비율
colors = pal3)       # 단어 색색
noun2 <- noun2[nchar(noun2) > 1] # 길이가 1글자 이하인것들 제외
noun2 <- gsub('하지', '', noun2) # 특정 단어를 공백으로 변경
noun2 <- gsub('때문', '', noun2) # 특정 단어를 공백으로 변경
noun2 <- gsub('들이', '', noun2)
wordcount <- table(noun2)
sort(wordcount)
wordcloud(names(wordcount),    # 단어
freq = wordcount,    # 단어 빈도
scale = c(6,0.7),    # 단어 폰트 크기(최대,최소)
min.freq = 3,        # 단어 최소 빈도
random.order = F,    # 단어 출력위치
rot.per = .1,        # 90도 회전 단어 비율
colors = pal3)       # 단어 색색
wordcloud(names(wordcount),    # 단어
freq = wordcount,    # 단어 빈도
scale = c(6,0.7),    # 단어 폰트 크기(최대,최소)
min.freq = 3,        # 단어 최소 빈도
random.order = F,    # 단어 출력위치
rot.per = .1,        # 90도 회전 단어 비율
colors = pal3)       # 단어 색색
#     6.2 불필요한 단어 삭제
noun2 <- noun2[nchar(noun2) > 1] # 길이가 1글자 이하인것들 제외
noun2 <- gsub('하지', '', noun2) # 특정 단어를 공백으로 변경
noun2 <- gsub('때문', '', noun2) # 특정 단어를 공백으로 변경
noun2 <- gsub('들이', '', noun2)
wordcount <- table(noun2)
sort(wordcount)
wordcloud(names(wordcount),    # 단어
freq = wordcount,    # 단어 빈도
scale = c(6,0.7),    # 단어 폰트 크기(최대,최소)
min.freq = 3,        # 단어 최소 빈도
random.order = F,    # 단어 출력위치
rot.per = .1,        # 90도 회전 단어 비율
colors = pal3)       # 단어 색색
wordcloud(names(wordcount),    # 단어
freq = wordcount,    # 단어 빈도
scale = c(6,0.7),    # 단어 폰트 크기(최대,최소)
min.freq = 3,        # 단어 최소 빈도
random.order = F,    # 단어 출력위치
rot.per = .1,        # 90도 회전 단어 비율
colors = pal3)       # 단어 색색
library(KoNLP)
useSystemDic()
useSejongDic()
useNIADic()
#
#
# 애국가 가사 :
# https://mois.go.kr/frt/sub/a06/b08/nationalIcon_3/screen.do
#
# 1. 사전 설정
useSejongDic()
# 2. 텍스트 데이터 가져오기
word_data <- readLines('애국가(가사),txt')
# 2. 텍스트 데이터 가져오기
word_data <- readLines('애국가(가사).txt')
# 2. 텍스트 데이터 가져오기
word_data <- readLines('애국가(가사).txt')
word_data
# 3. 명사 추출
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F)
word_data2
add_words <- c('백두산', '남산', '철갑', '가을', '하늘', '달')
buildDictionary( user_dic = data.frame(add.words),
rep('ncn',length(add_words)),
replace_usr_dic = T)
# 3.1  제대로 추출되징 ㅏㄶ은 단어를 사용자 사전에 등록
add_words <- c('백두산', '남산', '철갑', '가을', '하늘', '달')
buildDictionary( user_dic = data.frame(add.words),
rep('ncn',length(add_words)),
replace_usr_dic = T)
buildDictionary( user_dic =
data.frame(add.words,
rep('ncn',length(add_words))),
replace_usr_dic = T)
get_dictionary('user_dic')
add_words <- c('백두산', '남산', '철갑', '가을', '하늘', '달')
buildDictionary( user_dic =
data.frame(add.words,
rep('ncn',length(add_words))),
replace_usr_dic = T)
add_words <- c('백두산', '남산', '철갑', '가을', '하늘', '달')
buildDictionary( user_dic =
data.frame(add_words,
rep('ncn',length(add_words))),
replace_usr_dic = T)
get_dictionary('user_dic')
# 3.2 단어 추가 후 다시 명사 추출
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F)
word_data2
word_data2
# 3.1  제대로 추출되징 않은 단어를 사용자 사전에 등록
add_words <- c('백두산', '남산', '철갑', '가을', '하늘', '달','삼천리')
buildDictionary( user_dic =
data.frame(add_words,
rep('ncn',length(add_words))),
replace_usr_dic = T)
# 3.2 단어 추가 후 다시 명사 추출
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F)
word_data2
# 3.1  제대로 추출되징 않은 단어를 사용자 사전에 등록
add_words <- c('백두산', '남산', '철갑', '가을', '하늘', '달','삼천리')
buildDictionary( user_dic =
data.frame(add_words,
rep('ncn',length(add_words))),
replace_usr_dic = T)
get_dictionary('user_dic')
# 3.2 단어 추가 후 다시 명사 추출
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F)
word_data2
# 3.1  제대로 추출되징 않은 단어를 사용자 사전에 등록
add_words <- c('삼천리','백두산', '남산', '철갑', '가을', '하늘', '달')
buildDictionary( user_dic =
data.frame(add_words,
rep('ncn',length(add_words))),
replace_usr_dic = T)
get_dictionary('user_dic')
# 3.2 단어 추가 후 다시 명사 추출
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F)
word_data2
# 4. 행렬을 벡터로 변환
undata <- unlist(word_data2)
undata
# 5. 사용 빈도 확인
word_table <- table(undata)
word_table
# 6. 필터링 : 두 글자 이상 단어만 선별,
#             공백이나 한 자리 문자를 걸러냄
undata2 <- undata[nchar(undata) >= 2]
undata2
word_table <- table(undata2)
word_table
# 5. 사용 빈도 확인
word_table <- table(undata)
word_table
# 6. 필터링 : 두 글자 이상 단어만 선별,
#             공백이나 한 자리 문자를 걸러냄
undata2 <- undata[nchar(undata) >= 2]
undata2
word_table2 <- table(undata2)
word_table2
# 8. word cloud 작성
library(wordcloud2)
wordcloud2(word_table2,)
wordcloud2(word_table2,)
wordcloud2(word_table2,)
wordcloud2(word_table2,)
wordcloud2(word_table2,)
wordcloud2(word_table2,)
wordcloud2(word_table2,)
wordcloud2(word_table2,)
wordcloud2(word_table2,)
# 8.1 배경 및
wordcloud2(word_table2,
color = 'random-light',
backgroundColor = 'black')
source('D:/lyt09/workR/실습파일/12 일차 text 마이닝.R', encoding = 'UTF-8')
# 8.2 모양 변경
wordcloud2(word_table2,
fontFamily = '맑은고딕',
size = 1.2, color = 'random-light',
backgroundColor = 'black',
shape = 'star')
# 8.2 모양 변경
wordcloud2(word_table2,
fontFamily = '맑은고딕',
size = 1.2, color = 'random-light',
backgroundColor = 'black',
shape = 'star')
# 8.2 모양 변경
wordcloud2(word_table2,
fontFamily = '맑은고딕',
size = 1.2, color = 'random-light',
backgroundColor = 'black',
shape = 'star')
# 8.2 모양 변경
wordcloud2(word_table2,
fontFamily = '맑은고딕',
size = 1.2, color = 'random-light',
backgroundColor = 'black',
shape = 'diamond')
# 8.3 선택 색상 반복
wordcloud2(word_table2, size = 1.6,
color = rep_len(c('red','blue'),
nrow(word_table2)))
wordcloud2(demoFreq, size = 1.6,
color = rep_len(c('red','blue'),
nrow(word_table2)))
wordcloud2(demoFreq, size = 1.6,
color = rep_len(c('red','blue'),
nrow(word_table2)),
shape = 'star')
wordcloud2(demoFreq, size = 1.6,
color = 'random-light',
nrow(word_table2)),
shape = 'star')
wordcloud2(demoFreq, size = 1.6,
color = 'random-light',
nrow(word_table2),
shape = 'star')
wordcloud2(demoFreq, size = 1.6,
color = rep_len(c('red','blue'),
nrow(word_table2)),
shape = 'diamond')
wordcloud2(word_table2,
minRotation = -pi / 6,
maxRotation = -pi / 6,
rotateRatio =  1 )
wordcloud2(demoFreq,
minRotation = -pi / 6,
maxRotation = -pi / 6,
rotateRatio =  1 )
# 8.4 일정 방향 정렬
wordcloud2(word_table2,
minRotation = -pi / 6,
maxRotation = -pi / 6,
rotateRatio =  1 )
wordcloud2(demoFreq,
minRotation = -pi / 6,
maxRotation = -pi / 6,
rotateRatio =  1 )
#
# R 에서 웹문서 가져오기
#
# 웹에 있는 데이터를 가져오는 단계
#     요청: GET과 POST 방식
#     추출 및 저장
# 관련 R 패키지
#   XML, RCurl, httr, rvest, …
#
#
install.packages( "rvest" )
## 패키지 불러오기
library(rvest)
library(dplyr)
## 변수 입력하기
QUERY <- "제주" # 검색키워드
DATE  <- as.Date( as.character( 20191211 ), format = "%Y%m%d" ) # 검색시작날짜 & 검색종료날짜
DATE  <- format( DATE, "%Y.%m.%d" )
PAGE  <- 1
naver_url_1 <- "https://search.naver.com/search.naver?&where=news&query="
naver_url_2 <- "&pd=3&ds="
naver_url_3 <- "&de="
naver_url_4 <- "&start="
## 날짜 리스트 만들기
DATE_START <- as.Date( as.character( 20191211 ), format = "%Y%m%d" ) # 시작일자
DATE_END   <- as.Date( as.character( 20191211 ), format = "%Y%m%d" ) # 종료일자
DATE <- DATE_START:DATE_END
DATE <- as.Date( DATE, origin = "1970-01-01" )
## 게시물 번호 리스트 만들기
PAGE <- seq( from = 1, to = 41, by = 10 ) # 시작값과 종료값을 지정해줄 수 있습니다.
PAGE <- seq( from = 1, by = 10, length.out = 5) # 시작값과 원하는 갯수를 지정할 수도 있습니다.
## 네이버 검색결과 url 리스트에서 관련기사 url 리스트 만들기
news_url <- c()
news_date <-c()
for ( date_i in DATE ){
for ( page_i in PAGE ){
dt <- format( as.Date( date_i, origin = "1970-01-01" ), "%Y.%m.%d" )
naver_url <- paste0( naver_url_1, QUERY, naver_url_2, dt, naver_url_3, dt, naver_url_4, page_i )
html <- read_html( naver_url )
temp <- unique( html_nodes( html, '#main_pack' ) %>%     # id= 는 # 을 붙인다
html_nodes( css = '.news ' ) %>%         # class= 는 css= 를 붙인다
html_nodes( css = '.type01' ) %>%
html_nodes( 'a' )%>%
html_attr( 'href' ) )
news_url <- c( news_url, temp )
news_date <- c( news_date, rep( dt, length( temp ) ) )
}
print( dt ) # 진행상황을 알기 위함이니 속도가 느려지면 제외
}
NEWS0 <- as.data.frame( cbind( date = news_date, url = news_url, query = QUERY))
NEWS1 <- NEWS0[ which( grepl( "news.naver.com", NEWS0$url ) ), ]         # 네이버뉴스(news.naver.com)만 대상으로 한다
NEWS1 <- NEWS1[ which( !grepl( "sports.news.naver.com", NEWS1$url ) ), ] # 스포츠뉴스(sports.news.naver.com)는 제외한다
NEWS2 <- NEWS1[ !duplicated( NEWS1 ), ] # 중복된 링크 제거
## 뉴스 페이지에 있는 기사의 제목과 본문을 크롤링
NEWS2$news_title   <- ""
NEWS2$news_content <- ""
## 뉴스 페이지에 있는 기사의 제목과 본문을 크롤링
NEWS2$news_title   <- ""
NEWS2$news_content <- ""
for ( i in 1:dim( NEWS2 )[ 1 ] ){
html <- read_html( as.character( NEWS2$url[ i ] ) )
temp_news_title   <- repair_encoding( html_text( html_nodes( html, '#articleTitle' ) ), from = 'utf-8' )
temp_news_content <- repair_encoding( html_text( html_nodes( html, '#articleBodyContents') ), from = 'utf-8' )
if ( length( temp_news_title ) > 0 ) {
NEWS2$news_title[ i ]   <- temp_news_title
NEWS2$news_content[i] <- temp_news_content
}
}
NEWS2$news_content <- gsub( "// flash 오류를 우회하기 위한 함수 추가\nfunction _flash_removeCallback()", "", NEWS2$news_content )
NEWS <- NEWS2 # 최종 결과 저장
NEWS
NEWS$news_content
NEWS
# 워드클라우드
library( KoNLP )
useSejongDic()
word_data <- sapply( NEWS$news_content, extractNoun, USE.NAMES = F )
word_data
undata <- unlist( word_data )
undata
word_table <- table( undata )
word_table
undata2 <- undata[ nchar( undata ) >= 2 ]
undata2
word_table2 <- table( undata2 )
word_table2
sort( word_table2, decreasing = T )
library( wordcloud2 )
wordcloud2( word_table2, minRotation = -pi / 6, maxRotation = -pi / 6, rotateRatio = 1 )
wordcloud2( word_table2, minRotation = -pi / 6, maxRotation = -pi / 6, rotateRatio = 1 )
setwd('D:/lyt09/문제')
setwd('D:/lyt09/문제/1211')
mun1 <- readLines("ex_10-1.txt", encoding = "UTF-8")
mun1 <- readLines("ex_10-1.txt", encoding = "UTF-8")
mun2 <- readLines("ex_10-2.txt", encoding = "UTF-8")
mun3 <- readLines("ex_10-3.txt", encoding = "UTF-8")
mun3
buildDictionary(ext_dic = 'woorimalsam')
col1 <- brewer.pal(8,"Dark2")
mun1_1 <- sapply(mun1, extractNoun,USE.NAMES = F)
mun1_1
mun1_1 <- mun1_1[nchar(mun1_1 > 1)]
mun1_1 <- unlist(mun1_1)
mun1_1 <- sapply(mun1, extractNoun,USE.NAMES = F)
mun1_1 <- mun1_1[nchar(mun1_1 > 1)]
mun1_1 <- unlist(mun1_1)
mun1_1 <- mun1_1[nchar(mun1_1 > 1)]
wordmun1 <- table(mun1_1)
sort(wordmun1)
wordmun1
mun1_1 <- mun1_1[nchar(mun1_1 > 1)] # 1글자 이하제외
mun1_1
mun1 <- readLines("ex_10-1.txt", encoding = "UTF-8")
mun1_1 <- sapply(mun1, extractNoun,USE.NAMES = F)
mun1_1 <- unlist(mun1_1)
mun1_1
mun1_1 <- unlist(mun1_1)
mun1_1
mun1_1 <- mun1_1[nchar(mun1_1 > 1)] # 1글자 이하제외
mun1_1
mun1 <- readLines("ex_10-1.txt", encoding = "UTF-8")
mun1_1 <- sapply(mun1, extractNoun,USE.NAMES = F)
mun1_1 <- unlist(mun1_1)
mun1_1 <- mun1_1[nchar(mun1_1) > 1] # 1글자 이하제외
mun1_1
wordmun1 <- table(mun1_1)
sort(wordmun1)
wordcloud(wordmun1)
wordmun1 <- table(mun1_1)
wordcloud(wordmun1)
library(wordcloud)
library(wordcloud2)
wordcloud(wordmun1)
library(tm)
library(slam)
library(wordcloud)
library(wordcloud2)
library(KoNLP)
library(RColorBrewer)
library(dplyr)
library(ggplot2)
wordcloud(wordmun1)
library(KoNLP)
wordcloud(wordmun1)
wordcloud(names(wordmun1))
wordcloud2(wordmun1)
# 1-2
mun2_2 <- sapply(mun2, extractNoun,USE.NAMES = F)
mun2_2 <- unlist(mun2_2)
mun2_2 <- num2_2[nchar(mun2_2) > 1]
wordmun2 <- table(mun2_2)
wordcloud2(wordmun2)
mun2_2 <- mum2_2[nchar(mun2_2) > 1]
mun2_2 <- mun2_2[nchar(mun2_2) > 1]
# 1-2
mun2_2 <- sapply(mun2, extractNoun,USE.NAMES = F)
mun2_2 <- unlist(mun2_2)
mun2_2 <- mun2_2[nchar(mun2_2) > 1]
wordmun2 <- table(mun2_2)
wordcloud2(wordmun2)
# 1-2
mun2_2 <- sapply(mun2, extractNoun,USE.NAMES = F)
mun2_2 <- unlist(mun2_2)
mun2_2 <- mun2_2[nchar(mun2_2) > 1]
mun2_2 <- gsub("들이", "" , mun2_2)
mun2_2 <- gsub("해서", "" , mun2_2)
wordmun2 <- table(mun2_2)
wordcloud2(wordmun2)
# 1-3
mun3_1 <- sapply(mun3, extractNoun, USE.NAMES = F)
mun3_1 <- unlist(mun3_1)
mun3_1 <- mun3_1[nchar(mun3_1) > 1]
wordmun3 <- table(mun3_1)
wordcloud2(wordmun3)
steve <- readLines("ex_10-4.txt", encoding = "UTP-8")
steve <- readLines("ex_10-4.txt", encoding = "UTP-8")
st1 <- sapply(steve, extractNoun, USE.NAMES = F)
st1 <- unlist(st1)
st1 <- st1[nchar(st1) > 1]
stword <- table(st1)
wordcloud2(stword)
steve <- readLines("ex_10-4.txt", encoding = "UTF-8")
st1 <- sapply(steve, extractNoun, USE.NAMES = F)
st1 <- unlist(st1)
st1 <- st1[nchar(st1) > 1]
stword <- table(st1)
wordcloud2(stword)
obama <- readline("ex_10-5.txt", encoding = "UTF-8")
obama <- readLines("ex_10-5.txt", encoding = "UTF-8")
ob <- sapply(obama, extractNoun,USE.NAMES = F)
ob <- unlist(ob)
ob <- ob[nchar(ob)>1]
obword <- table(ob)
wordcloud2(obword)
wordcloud2(obword)
wordcloud2(obword,
minRotation = -pi/6,
maxRotation = -pi/6,
rotateRatio = 1)
brewer.pal
brewer.pal.info
palz <- brewer.pal(11,'Spectral')[6:11]
wordcloud2(obword,
minRotation = -pi/6,
maxRotation = -pi/6,
rotateRatio = 1,
color = palz)
palz <- brewer.pal(11,'Spectral')[1:11]
wordcloud2(obword,
minRotation = -pi/6,
maxRotation = -pi/6,
rotateRatio = 1,
color = palz)
palz <- brewer.pal(11,'Spectral')[1:5]
wordcloud2(obword,
minRotation = -pi/6,
maxRotation = -pi/6,
rotateRatio = 1,
color = palz)
palz <- brewer.pal(11,'Spectral')[3:7]
wordcloud2(obword,
minRotation = -pi/6,
maxRotation = -pi/6,
rotateRatio = 1,
color = palz)
brewer.pal.info
palz <- brewer.pal(8,'Blues')[1:6]
wordcloud2(obword,
minRotation = -pi/6,
maxRotation = -pi/6,
rotateRatio = 1,
color = palz)
palz <- brewer.pal(9,'Blues')[3:9]
wordcloud2(obword,
minRotation = -pi/6,
maxRotation = -pi/6,
rotateRatio = 1,
color = palz)
wordcloud2(obword,
minRotation = -pi/6,
maxRotation = -pi/6,
rotateRatio = 1,
color = rep_len(palz))
wordcloud2(obword,
minRotation = -pi/6,
maxRotation = -pi/6,
rotateRatio = 1,
color = rep_len('red','blue'))
wordcloud2(obword,
minRotation = -pi/6,
maxRotation = -pi/6,
rotateRatio = 1,
color = rep_len(c('red','blue')))
wordcloud2(obword,
color = rep_len( c('red','blue') ))
wordcloud2(obword,
color = rep_len( c('red','blue') ),
nrow(wordcloud2()))
wordcloud2(obword,
color = rep_len( c('red','blue') ),
nrow(ob()))
